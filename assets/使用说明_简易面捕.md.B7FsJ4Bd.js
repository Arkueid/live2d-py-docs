import{_ as a,c as t,a0 as i,o as r}from"./chunks/framework.Dz_4l__G.js";const o="/live2d-py-docs/video_test.gif",p="/live2d-py-docs/facial_capture.gif",h=JSON.parse('{"title":"简易面部动捕","description":"","frontmatter":{},"headers":[],"relativePath":"使用说明/简易面捕.md","filePath":"使用说明/简易面捕.md"}'),d={name:"使用说明/简易面捕.md"};function c(n,e,s,l,_,m){return r(),t("div",null,e[0]||(e[0]=[i('<h1 id="简易面部动捕" tabindex="-1">简易面部动捕 <a class="header-anchor" href="#简易面部动捕" aria-label="Permalink to &quot;简易面部动捕&quot;">​</a></h1><h2 id="简易面捕示例" tabindex="-1">简易面捕示例 <a class="header-anchor" href="#简易面捕示例" aria-label="Permalink to &quot;简易面捕示例&quot;">​</a></h2><p>使用 <code>opencv</code> + <code>mediapipe</code> 实现面部特征点识别，通过特征点的位置计算当前面部所处的状态，并映射到 live2d 模型的参数上，核心是 <code>LAppModel.SetParameterValue</code>。</p><p>源码见 <a href="https://github.com/Arkueid/live2d-py/tree/main/package/main_facial_bind_mediapipe.py" target="_blank" rel="noreferrer">main_facial_bind_mediapipe.py</a></p><p><img src="'+o+'" alt="期末周破防"></p><p><img src="'+p+'" alt="简易动捕"></p>',6)]))}const u=a(d,[["render",c]]);export{h as __pageData,u as default};
