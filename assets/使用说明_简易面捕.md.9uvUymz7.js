import{_ as e,c as a,o as t,a2 as r,aa as i,ab as o}from"./chunks/framework.BayvGiKz.js";const b=JSON.parse('{"title":"简易面部动捕","description":"","frontmatter":{},"headers":[],"relativePath":"使用说明/简易面捕.md","filePath":"使用说明/简易面捕.md"}'),_={name:"使用说明/简易面捕.md"},c=r('<h1 id="简易面部动捕" tabindex="-1">简易面部动捕 <a class="header-anchor" href="#简易面部动捕" aria-label="Permalink to &quot;简易面部动捕&quot;">​</a></h1><h2 id="简易面捕示例" tabindex="-1">简易面捕示例 <a class="header-anchor" href="#简易面捕示例" aria-label="Permalink to &quot;简易面捕示例&quot;">​</a></h2><p>使用 <code>opencv</code> + <code>mediapipe</code> 实现面部特征点识别，通过特征点的位置计算当前面部所处的状态，并映射到 live2d 模型的参数上，核心是 <code>LAppModel.SetParameterValue</code>。</p><p>源码见 <a href="https://github.com/Arkueid/live2d-py/tree/main/package/main_facial_bind_mediapipe.py" target="_blank" rel="noreferrer">main_facial_bind_mediapipe.py</a></p><p><img src="'+i+'" alt="期末周破防"></p><p><img src="'+o+'" alt="简易动捕"></p>',6),p=[c];function d(n,s,l,m,h,f){return t(),a("div",null,p)}const k=e(_,[["render",d]]);export{b as __pageData,k as default};
